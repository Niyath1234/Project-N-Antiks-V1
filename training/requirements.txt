# Training dependencies for LoRA fine-tuning
torch>=2.0.0
transformers>=4.35.0
peft>=0.6.0
datasets>=2.14.0
accelerate>=0.24.0
sentencepiece>=0.1.99
protobuf>=3.20.0
tqdm>=4.65.0
numpy>=1.24.0

# YouTube transcript extraction
yt-dlp>=2023.0.0

# Model conversion
llama-cpp-python>=0.2.0

# API client
requests>=2.31.0
