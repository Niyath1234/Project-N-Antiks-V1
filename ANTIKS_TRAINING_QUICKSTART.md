# Antiks-v1 Training: Quick Start Guide

## âœ… System Check
All components tested and working:
- âœ… DeepSeek API (OpenRouter) - Working
- âœ… Challenge generation - Working
- âœ… Answer evaluation - Working
- âœ… Model loading - Ready
- âœ… MPS acceleration - Available

## ğŸš€ Start Training

### Option 1: Quick Test Run (2 iterations)
```bash
cd /Users/niyathnair/python_nn
source venv/bin/activate
python3 training/train_antiks_v1.py --iterations 2
```

### Option 2: Full Training (10 iterations - Recommended)
```bash
cd /Users/niyathnair/python_nn
source venv/bin/activate
python3 training/train_antiks_v1.py --iterations 10
```

### Option 3: With Initial Training on Existing Data
```bash
cd /Users/niyathnair/python_nn
source venv/bin/activate
python3 training/train_antiks_v1.py --initial_train --iterations 5
```

## ğŸ“Š What Happens

### Each Iteration:
1. ğŸ¤– **Teacher** generates 10 challenging SQL questions
2. ğŸ“ **Student** (Antiks) attempts to answer each
3. âœ… **Teacher** evaluates each answer (score 0-100)
4. ğŸ“ **Wrong answers** (<80 score) become training examples
5. ğŸ”„ **Model trains** on new examples
6. ğŸ“ˆ **Performance improves** over iterations

### Expected Output:
```
Iteration 1:
  Challenge 1: âœ… Score: 95 (no training needed)
  Challenge 2: âŒ Score: 45 (added to training)
  Challenge 3: âŒ Score: 60 (added to training)
  ...
  Saved 7 new training examples
  Training on 7 examples...
  
Iteration 2:
  Challenge 1: âœ… Score: 92 (no training needed)
  Challenge 2: âœ… Score: 88 (no training needed)
  ...
```

## â±ï¸ Time Estimates

| Iterations | Time | What You Get |
|------------|------|--------------|
| 2 | ~1 hour | Proof of concept |
| 5 | ~3 hours | Significant improvement |
| 10 | ~5 hours | Teacher-level performance |

## ğŸ“ Output Files

```
output_antiks_v1/
  â”œâ”€â”€ adapter_model.bin          # LoRA weights
  â”œâ”€â”€ adapter_config.json        # LoRA config
  â””â”€â”€ training_args.bin          # Training settings

checkpoints_antiks_v1_iter_N/    # Per-iteration checkpoints

active_learning_data/
  â””â”€â”€ active_learning_iter_N.jsonl  # Training examples per iteration
```

## ğŸ¯ Success Metrics

Watch for:
- âœ… Average score increases over iterations
- âœ… Fewer examples added per iteration (model getting smarter)
- âœ… Training loss decreases
- âœ… Model generates correct SQL more often

## ğŸ”„ After Training

### Deploy to Ollama:
```bash
# Convert to GGUF format
python training/convert_to_gguf.py

# Deploy
bash training/deploy_to_ollama.sh antiks-v1

# Test
ollama run antiks-v1 "Calculate year-over-year revenue growth"
```

### Test Performance:
```bash
python training/test_csv.py
```

## ğŸ› Troubleshooting

### API Rate Limits
If hitting rate limits, add delays in code or run fewer iterations at once.

### Memory Issues
If running out of memory:
- Reduce `batch_size` in CONFIG
- Reduce `max_length`
- Close other applications

### Long Training Times
Training on MPS is slower than CUDA. Consider:
- Running overnight
- Using cloud GPU
- Reducing `num_epochs` per iteration

## ğŸ“– Full Documentation

See `training/TRAIN_ANTIKS.md` for complete details.

## ğŸ‰ Ready?

```bash
python3 training/train_antiks_v1.py --iterations 5
```

Let's train Antiks-v1 to teacher-level! ğŸš€

